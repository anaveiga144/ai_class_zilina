{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpDXNUfuhJ41",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "uIGqXiLohJ5l",
    "outputId": "11327b67-570f-405f-9ea3-714bf445555e"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "5u1mk6jGhJ6q",
    "outputId": "a7cec16c-4661-4edf-f3af-956ccded10a5"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from skorch import NeuralNetClassifier, NeuralNet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "colab_type": "code",
    "id": "bApCnClBhJ7U",
    "outputId": "26dbfeca-0315-40cb-fcdb-56fc8c75db23"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "!mkdir -p data\n",
    "!mkdir -p output\n",
    "!wget -nc -O data/cat.jpg https://www.dropbox.com/s/a5ux951zo01gd5z/cat.jpg?dl=1\n",
    "!wget -nc -O data/imagenet_classes https://www.dropbox.com/s/ma25i7w3jpqex2a/imagenet_classes?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4eIWvyhhJ75"
   },
   "outputs": [],
   "source": [
    "#@title -- Auxiliary Functions -- { display-mode: \"form\" }\n",
    "with open(\"data/imagenet_classes\", \"r\") as file:\n",
    "    classes = [c[:-1] for c in file.readlines()]\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def preproc_image(img):\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    return batch_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKASxihFM7Rq",
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Using a Pre-trained Classifier\n",
    "\n",
    "This notebook will show a very simple example of loading and using a classifier pre-trained on ImageNet. We will show how it can be used to classify new images.\n",
    "# Loading the Model\n",
    "\n",
    "In the previous examples we have defined a class for our own neural net and specified its architecture. Now we will instead use one of the predefined models with pretrained weights. These models are available in the ``torchvision.models`` package. We will use architecture ``densenet169`` in particular and specify the argument ``pretrained=True`` when creating an instance. This means that the network is to be initialized with weights pretrained on the ImageNet dataset. If we are calling this piece of code for the first time, the weight will need to be downloaded over the internet first.\n",
    "\n",
    "To load a model we could also use the ``torch.hub`` tool – in that case the model would not have to be built into PyTorch. We could instead load it directly from one of the special GitHub repositories that support this. For instance, we could load the well-known EfficientNetB0 using the following code:\n",
    "```python\n",
    "torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "cf03e7d384ec4961938e358af3d6bb95",
      "6077b9616e1f47a6b13ebf2af7a3675f",
      "fc22628b7e804a94bbf26295a1010bf1",
      "d4ddf7cd4047436ea1416cad8b33dd39",
      "5810de579c5c4bc58d33ee1f15cd4a3d",
      "0671d72782394f388f1ccf9f3aa00c9b",
      "fad7652604204d328871d00ee231e86d",
      "22fbcecd23014d709bd103b7c402d762"
     ]
    },
    "colab_type": "code",
    "id": "g-U4h6xshJ8b",
    "outputId": "3c7a4e4d-1b04-4afc-88b0-34fe964a47b4"
   },
   "outputs": [],
   "source": [
    "module = models.densenet169(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9m2MNw-M7R8",
    "tags": [
     "en"
    ]
   },
   "source": [
    "When creating a classifier we will now only need to specify the instance of our model and specify the device that we want to use. In our case we will, however, need to append a softmax layer to the end of the network – networks from ``torchvision.models`` do not have a softmax layer because the loss function they were trained incorporated it. We are not going to train the model and therefore we also need to call function ``initialize``, which will make the network ready for inference (the pretrained weights will of course not be replaced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9-kFWrIhJ8x"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    torch.nn.Sequential(module, torch.nn.Softmax()),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "net.initialize();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ-dVy7pM7SP",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Using the Model\n",
    "\n",
    "We load and preprocess the image that we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Mq0YGlmqhJ9E",
    "outputId": "24c4d4d3-0aa8-4329-c7e0-e4010030a544"
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"data/cat.jpg\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2x8ifLZsM7Sf",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Before plugging the image into the network we will need to apply some slight preprocessing using function ``preproc_image``. This is because we need to ensure that images are preprocessed in the same way as when the network was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gZgEBt8DhJ9V",
    "outputId": "a6421536-1e8f-46aa-e700-47d2c010fff9"
   },
   "outputs": [],
   "source": [
    "img_prep = preproc_image(img)\n",
    "y = net.predict(img_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4h3i3IjiM7Sv",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The network will return the number of the class. The list of class labels is stored in the ``classes`` list (it was read from a file in the auxiliary code section), so we only need to index it using the output of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MaVRWVu4hJ9l",
    "outputId": "400a24e1-57a0-465b-aa02-c194bd9aa659"
   },
   "outputs": [],
   "source": [
    "classes[y.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mu-AO6xuM7S9",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Displaying the Top-5 Predictions\n",
    "\n",
    "Given that our network actually predicts class probabilities, we might want to known about those and not just about the label of the most probable class. In fact, let's display the top-5 predictions and their probabilities. This will give us a better idea of how confident the neural network is about its prediction and whether the other, less probable predictions make any sense or not.\n",
    "\n",
    "Our neural classifier has an interface for querying about probabilities: we can use the ``predict_proba`` method, which is also available in a number of different ``scikit-learn`` classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "j2267SnhhJ-I",
    "outputId": "d3cabaf7-87c0-4404-8258-c7aad0feaf0c"
   },
   "outputs": [],
   "source": [
    "proba = net.predict_proba(img_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTZTyuEaM7TM",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Once we have got the probabilities, all we need to do is to sort them and identify the classes with the top-5 probabilities. To this end we will define a small auxiliary function and apply it to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mfj0eumDhJ94"
   },
   "outputs": [],
   "source": [
    "def decode_proba(proba, top=5):\n",
    "    proba = proba.ravel()\n",
    "    ind = np.argsort(proba)\n",
    "    \n",
    "    for c in reversed(ind[-top:]):\n",
    "        print(\"{}:\\t{} ({})\".format(\n",
    "            np.array2string(proba[c], precision=5),\n",
    "            classes[c], c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "uzg8q1lIhJ-g",
    "outputId": "08e8826f-5122-4b6a-8d69-5a51a99f5c2e"
   },
   "outputs": [],
   "source": [
    "decode_proba(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlA1JLRFM7Tg",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "\n",
    "## Task 1: Predictions about Other Images\n",
    "\n",
    "**Try to apply the same procedure to a different image.**\n",
    "\n",
    "Note: New images can be uploaded **directly through the notebook interface** or else using:\n",
    "```python\n",
    "from google.colab import files\n",
    "content_img = files.upload()\n",
    "filename = list(content_img)[0]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJTJWW68hJ_v",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j5QLavr5M7T6",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The list of classes that the network is supposed to be able to classify can be found in file ``data/imagenet_classes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43lL_W0RhKAB",
    "outputId": "4b019816-ac3d-4bc2-cb0a-3556804b061b"
   },
   "outputs": [],
   "source": [
    "for ic, c in enumerate(classes):\n",
    "    print(\"{}:\\t{}\".format(ic, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRImKJeYM7UG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "5_imagenet_pretrained.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0671d72782394f388f1ccf9f3aa00c9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22fbcecd23014d709bd103b7c402d762": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5810de579c5c4bc58d33ee1f15cd4a3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6077b9616e1f47a6b13ebf2af7a3675f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf03e7d384ec4961938e358af3d6bb95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc22628b7e804a94bbf26295a1010bf1",
       "IPY_MODEL_d4ddf7cd4047436ea1416cad8b33dd39"
      ],
      "layout": "IPY_MODEL_6077b9616e1f47a6b13ebf2af7a3675f"
     }
    },
    "d4ddf7cd4047436ea1416cad8b33dd39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22fbcecd23014d709bd103b7c402d762",
      "placeholder": "​",
      "style": "IPY_MODEL_fad7652604204d328871d00ee231e86d",
      "value": "100% 54.7M/54.7M [00:01&lt;00:00, 37.2MB/s]"
     }
    },
    "fad7652604204d328871d00ee231e86d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc22628b7e804a94bbf26295a1010bf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0671d72782394f388f1ccf9f3aa00c9b",
      "max": 57365526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5810de579c5c4bc58d33ee1f15cd4a3d",
      "value": 57365526
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
