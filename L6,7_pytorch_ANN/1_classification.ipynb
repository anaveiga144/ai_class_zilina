{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXDlX-V-K7K3",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "homwYbPNTMuF",
    "outputId": "e23cd139-6594-4b54-bfe6-5e2c742dfd35"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Z5iLk5oyTABe",
    "outputId": "0c95eabd-1c0c-4cc6-b396-055cac14eeb9"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "ZFdF9__eTCta",
    "outputId": "f17db9c6-f26a-4007-c2a1-32c1ff937c75"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "!mkdir -p output\n",
    "!mkdir -p data\n",
    "!wget -nc -O data/iris.csv https://www.dropbox.com/s/v3ptdkv5fvmx5zk/iris.csv?dl=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sRXDh_BK7MN",
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Neural Network Classifiers\n",
    "\n",
    "This notebook deals with the application of a neural network constructed using the ``keras`` python package to a simple classification task. We will show how a network can be created and trained. We will use a very simple architecture – no convolutional layers, batch normalization or anything like that.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "In this example, we will again be using the Iris dataset, with which we are very familiar by now. We will now load it from the CSV file and split it into the train and test folds:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ2bVFL7TVT0"
   },
   "source": [
    "# Klasifikácia pomocou umelých neurónových sietí\n",
    "\n",
    "Tento notebook ukazuje, ako sa dá neurónová sieť zostrojená pomocou pythonového balíčka ``pytorch`` aplikovať na jednoduchú klasifikačnú úlohu. Ukážeme, ako sa dá taká sieť vytvoriť a natrénovať. Budeme používať veľmi jednoduchú architektúru – bez konvolučných vrstiev, dávkovej normalizácie a iných podobných špeciálnych vrstiev.\n",
    "\n",
    "## Načítanie dátovej množiny\n",
    "\n",
    "V tomto príklade budeme opäť pracovať s dátovou množinou Iris, ktorú už dobre poznáme. Teraz ju načítame z CSV súboru a rozdelíme na tréningovú a testovaciu časť:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "g0gqtIoXTEmo",
    "outputId": "89e2ceed-7659-4e5d-fa5c-e33628fcb368"
   },
   "outputs": [],
   "source": [
    "#@title -- Loading and Splitting the dataset df_train, df_test -- { display-mode: \"form\" }\n",
    "\n",
    "# we load the data from the CSV\n",
    "df = pd.read_csv(\"data/iris.csv\")\n",
    "display(df.head())\n",
    "\n",
    "# we split it into train and test, stratifying by species\n",
    "df_train, df_test = train_test_split(df, test_size=0.25,\n",
    "                                     stratify=df['species'],\n",
    "                                     random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDhmP7paK7Mm",
    "tags": [
     "en"
    ]
   },
   "source": [
    "As usual, we sort the columns into categorical, numerical and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEDV74K8K7Mu"
   },
   "outputs": [],
   "source": [
    "categorical_inputs = []\n",
    "numeric_inputs = list(df.columns[:-1])\n",
    "output = [\"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PONQKCuK7M7",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The preprocessing that we have standardly applied up till now re-encodes categorical attributes into numbers, by assigning a number to each unique value of the attribute (using the ``OrdinalEncoder`` transformer). In the case of neural networks it will usually be more suitable to use one-hot encoding instead: for each categorical column there will be as many input neurons as there are distinct categorical values and exactly one out of these will be active at any given time. This kind of preprocessing can be achieved using the ``OneHotEncoder`` transformer. The preprocessing for numeric values can remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEWqq4NRK7NH"
   },
   "outputs": [],
   "source": [
    "input_preproc = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='MISSING'),\n",
    "        OneHotEncoder()),\n",
    "     categorical_inputs),\n",
    "    \n",
    "    (make_pipeline(\n",
    "        SimpleImputer(),\n",
    "        StandardScaler()),\n",
    "     numeric_inputs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C4Q34A1K7NU"
   },
   "outputs": [],
   "source": [
    "output_preproc = OrdinalEncoder()\n",
    "\n",
    "X_train = input_preproc.fit_transform(df_train[categorical_inputs+numeric_inputs])\n",
    "Y_train = output_preproc.fit_transform(df_train[output]).reshape(-1)\n",
    "\n",
    "X_test = input_preproc.transform(df_test[categorical_inputs+numeric_inputs])\n",
    "Y_test = output_preproc.transform(df_test[output]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYVnNoNbK7Ne",
    "tags": [
     "en"
    ]
   },
   "source": [
    "In addition to our standard preprocessing, we will also transform the results into datatypes expected by PyTorch: i.e. into 32-bit floats (inputs) and 64-bit ints (class labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0lv19niTWuq"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.int64)\n",
    "X_test = X_test.astype(np.float32)\n",
    "Y_test = Y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fx1fXxzoK7Nz",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating the Neural Network\n",
    "\n",
    "In order to create our neural net, we will inherit from the base class ``nn.Module``. The way in which all the layers are connected is defined in method ``forward``, which receives the input tensor as its argument and returns the output tensor. All layers with learnable parameters are created in the constructor. Layers which do not have any learnable parameters can be applied directly inside``forward``.\n",
    "\n",
    "A neural net must have a certain fixed number of input and output neurons. The number of inputs will equal the number of columns in our dataset. The number of columns, on the other hand, will equal the number of classes, since the network is going to return their probabilities. The activation function of the output layer will be the softmax function, which will ensure that the outputs of the last layer will always sum up to 1, so that they can really be interpreted as properly normalized probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXI0Wb9dINWw"
   },
   "outputs": [],
   "source": [
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = len(np.unique(Y_train))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc1(x)\n",
    "        y = torch.relu(y)\n",
    "        \n",
    "        y = self.fc2(y)\n",
    "        y = torch.relu(y)\n",
    "        \n",
    "        y = self.fc3(y)\n",
    "        y = torch.softmax(y, dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pz5vyIi-K7OG",
    "tags": [
     "en"
    ]
   },
   "source": [
    "Our neural net can either use the processor or the graphics card (GPU), if it is available. We can specify the type of device that we intend to use. Our code will automatically select the \"cuda\" device (the GPU), if it is available, or \"cpu\" (the processor) if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3Y-9kHoINTd"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zn0ySi8HK7OY",
    "tags": [
     "en"
    ]
   },
   "source": [
    "The next step is to create the classifier itself – it will be an instance of class ``NeuralNetClassifier`` from the ``skorch`` package, which will wrap our neural net into the standard ``scikit-learn`` interface, which will make it significantly easier to run the training, but which will also enable us to use the net as a part of a pipeline, should we need to.\n",
    "\n",
    "When constructing the classifier we can enter a number of parameters. We are only going to show a handful (the rest can, of course, be found in the documentation):\n",
    "* max_epochs: the number of learning epochs (how may times we are going to iterate over the entire dataset);\n",
    "* batch_size: size of the mini-batches – when -1 is specified, this means that the entire dataset will be used, i.e. we will be training in the full-batch mode;\n",
    "* optimizer: specifies which optimization method will be used;\n",
    "* train_split: specifies how the data will be split into training and validation folds – None means that the entire dataset is going to be used for training and there will be no validation set (note that we are not talking about the testing set here, which we have already separated manually – the validation set is used during training, e.g. for early stopping or for hyperparameter tuning etc.);\n",
    "* device: specifies which device is going to be used (the procesor or cuda). \n",
    "\n",
    "If we wanted to parametrize the individual components that make up the classifier, we can use parameters with prefixes in the form of ``prefix__parameter_name``. If, for instance, we wanted to change the learning rate used by the optimizer, we would use the following parameter:\n",
    "```\n",
    "optimizer__lr=value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUCSFjAWINPx"
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    Net,\n",
    "    max_epochs=100,\n",
    "    batch_size=-1,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJyeQc78K7Op",
    "tags": [
     "en"
    ]
   },
   "source": [
    "And now we can finally run the training – the interface is the same as that of all ``scikit-learn`` classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-2mSGkS6INL5",
    "outputId": "8f56c8f6-5e07-4f5d-da20-bed7d48a9820"
   },
   "outputs": [],
   "source": [
    "net.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lBsnW4MK7O7",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Testing\n",
    "\n",
    "Now that we have trained our model, we need to test its performance.\n",
    "\n",
    "### On Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6hhikUlINIT"
   },
   "outputs": [],
   "source": [
    "y_train = net.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "QBg9CnISPHf5",
    "outputId": "596a88d8-d760-46fb-99c7-17255e7d7317"
   },
   "outputs": [],
   "source": [
    "cm = pd.crosstab(\n",
    "    output_preproc.inverse_transform(\n",
    "        Y_train.reshape(-1, 1)).reshape(-1),\n",
    "    output_preproc.inverse_transform(\n",
    "        y_train.reshape(-1, 1)).reshape(-1),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-OMdQEE4PHpt",
    "outputId": "ccddaaa0-c195-416d-b3a0-e04a2c7333a3"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_train, y_train)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTzTPfMLK7Pl",
    "tags": [
     "en"
    ]
   },
   "source": [
    "### On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7TxulfVPUCl"
   },
   "outputs": [],
   "source": [
    "y_test = net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "31Ez6D75PSb7",
    "outputId": "4dfdc972-7d2c-41f4-d87b-185410f8b05f"
   },
   "outputs": [],
   "source": [
    "cm = pd.crosstab(\n",
    "    output_preproc.inverse_transform(\n",
    "        Y_test.reshape(-1, 1)).reshape(-1),\n",
    "    output_preproc.inverse_transform(\n",
    "        y_test.reshape(-1, 1)).reshape(-1),\n",
    "    rownames=['actual'],\n",
    "    colnames=['predicted']\n",
    ")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5IB3nwHnPSgV",
    "outputId": "47055b05-2f92-44fe-f4dd-ea8c4fa77b40"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_test, y_test)\n",
    "print(\"Accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8709uN5wK7QY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "1_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
