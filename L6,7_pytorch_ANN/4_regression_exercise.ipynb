{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8rFleQJMA18",
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform, which provides free hardware acceleration. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook, using a local GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uYHzZMVjMA2N",
    "outputId": "29d36ada-9af4-423c-eff7-81209ed8d247"
   },
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install skorch\n",
    "!{sys.executable} -m pip install git+https://github.com/michalgregor/class_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "yn6Mqh5qMA2r",
    "outputId": "47da0c29-a06a-4711-e014-5d7898083f73"
   },
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "from class_utils import error_histogram\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jLWb1LkMMA2-",
    "outputId": "f752dd34-0ffd-4ede-cef3-f0cb156833d5"
   },
   "outputs": [],
   "source": [
    "#@title -- Downloading Data -- { display-mode: \"form\" }\n",
    "!mkdir -p output\n",
    "!mkdir -p data/boston_housing\n",
    "!wget -nc -O data/boston_housing.zip https://www.dropbox.com/s/3jnf3000vwaxtcg/boston_housing.zip?dl=1\n",
    "!unzip -oq -d data/boston_housing data/boston_housing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRv3uQX8MA3P",
    "tags": [
     "en"
    ]
   },
   "source": [
    "# A Real-Estate-Price Regression Model\n",
    "\n",
    "In this notebook we will apply neural regression to the problem of real estate price prediction. We will make use of the [Boston housing dataset](https://www.kaggle.com/c/boston-housing).\n",
    "\n",
    "## Loading and Splitting the Dataset\n",
    "\n",
    "Let us start by displaying the description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "colab_type": "code",
    "id": "vMO0LT4CMA3b",
    "outputId": "fdf7983e-d5b7-46b7-ed70-98e4f49ba507"
   },
   "outputs": [],
   "source": [
    "with open(\"data/boston_housing/description.txt\", \"r\") as file:\n",
    "    print(\"\".join(file.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwIdli9oMA3u",
    "tags": [
     "en"
    ]
   },
   "source": [
    "As the next step, we will load the dataset itself from a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "XlH4mJwxMA32",
    "outputId": "6e8bade1-20a8-4a8b-a3c6-2f97ce5e003d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/boston_housing/housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UA381bPMA4D",
    "tags": [
     "en"
    ]
   },
   "source": [
    "We will split the data into the train and test set, stratifying by the discretized version of the output column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89Qbm_CvMA4L"
   },
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(10, encode='ordinal')\n",
    "y_stratify = kbins.fit_transform(df[[\"medv\"]])\n",
    "df_train, df_test = train_test_split(df, stratify=y_stratify,\n",
    "                        test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdVDQvxjMA4V",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "## Task 1: Data Preprocessing\n",
    "\n",
    "**Apply our standard preprocessing procedure for neural nets to the data and produce the training set ``X_train``, ``Y_train`` and the testing set ``X_test``, ``Y_test`` as the result: in the necessary form and cast to the appropriate data type.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqWPdiMmMA4m",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_inputs = [          ] # -----\n",
    "\n",
    "numeric_inputs = [              ] # -----\n",
    "\n",
    "output = [\"medv\"]\n",
    "\n",
    "\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "output_preproc = StandardScaler()\n",
    "\n",
    "\n",
    "# -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-1N5WV3MA4x",
    "tags": [
     "en"
    ]
   },
   "source": [
    "---\n",
    "## Task 2: Creation of Neural Net and Training\n",
    "\n",
    "**Create a neural regressor and train it using the train set. The result should be a trained ``net`` object with a ``scikit-learn`` interface, the performance of which we will subsequently be able to test using the test set.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXtcSROsMA5N",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_inputs = X_train.shape[1]\n",
    "num_outputs = Y_train.shape[1]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # -----\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    Net,\n",
    "    max_epochs=200,\n",
    "    batch_size=-1,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "few47apAMA5X",
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "net.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIPdcMu4MA5g",
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Testing\n",
    "\n",
    "We verify generalization using the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "w2d6xYOZMA5n",
    "outputId": "c6ebf6a7-ac65-4ac2-dac9-63cb52999185"
   },
   "outputs": [],
   "source": [
    "#@title -- Testing -- { display-mode: \"form\" }\n",
    "y_test = net.predict(X_test)\n",
    "min_output = np.min(Y_test)\n",
    "max_output = np.max(Y_test)\n",
    "\n",
    "# we compute and display the MSE and the MAE\n",
    "mse = mean_squared_error(Y_test, y_test)\n",
    "print(\"MSE = {}\".format(mse))\n",
    "\n",
    "mae = mean_absolute_error(Y_test, y_test)\n",
    "print(\"MAE = {}\".format(mae))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "error_histogram(Y_test, y_test, Y_fit_scaling=Y_train)\n",
    "plt.savefig(\"output/error_output_histogram.pdf\", bbox_inches='tight', ppad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rf4pq1eqMA51"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "name": "4_regression_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
