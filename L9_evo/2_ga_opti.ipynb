{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**NOTE: This notebook is written for the Google Colab platform. However it can also be run (possibly with minor modifications) as a standard Jupyter notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Installation of Packages -- { display-mode: \"form\" }\n",
    "import sys\n",
    "!{sys.executable} -m pip install inspyred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title -- Import of Necessary Packages -- { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "import inspyred\n",
    "from random import Random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Genetic Algorithms and Optimization\n",
    "\n",
    "We have already considered some optimization methods in earlier notebooks, including **ordinary least squares** (for linear regression) and **gradient descent** (for logistic regression, neural nets, etc.). We can use ordinary least squares to compute a closed-form solution to linear regression. For non-linear systems we usually can't give a closed-form solution and the optimization needs to be done iteratively: and gradient descent is one of the methods that can be applied.\n",
    "\n",
    "We have also mentioned one of the disadvantages of gradient-based optimization method: for non-convex functions, they are not guaranteed to find the global optimum. They can get trapped in a local optimum, or even a saddle point. A further disadvantage that we have not discussed as much is that the approach is not easy to apply when it is hard to get a good analytic description of the objective function and/or the objective function is not differentiable.\n",
    "\n",
    "In the next few notebooks we will consider a different kind of optimization methods: the so-called evolutionary methods, especially genetic algorithms. These methods do not guarantee that the global optimum will be found either, but they are less likely to get trapped in local optima and they can often get reasonable results in not too long a time. They do not have any very strong requirements concerning the structure of the problem, they work with non-differentiable functions, etc. For this reason, they might be worth looking into for some problems.\n",
    "\n",
    "On the other hand, evolutionary methods are typically not especially effective. When other approaches to the same problem exist, they will often be much more effective than an evolutionary approach. Sometimes one can achieve good results by hybridizing some such existing solution with an evolutionary approach.\n",
    "\n",
    "These notebooks will show how to apply some simple evolutionary approaches in Python.\n",
    "\n",
    "## The Objective Function\n",
    "\n",
    "As usual, we will start by defining the objective function that we are going to be optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x, y):\n",
    "    nom = 1 - (np.sin(0.5 * np.sqrt(x**2 + y**2)))**2\n",
    "    denom =  1 + 0.001*(x**2 + y**2)\n",
    "    return 1 - nom / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Let us visualize the function to make things more concrete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "xx, yy = np.mgrid[-20:20.05:0.25, -20:20.05:0.25]\n",
    "zz = criterion(xx, yy)\n",
    "\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "ax.plot_surface(xx, yy, zz, rstride=1, cstride=1, cmap='Spectral')\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "ax.set_zlabel(\"$f(x, y)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "As we can see, the function has a number of minima. However, there is just one global minimum, which is at (0, 0).\n",
    "\n",
    "## Genetic Algorithms\n",
    "\n",
    "Next we will define a few components that genetic algorithms require.\n",
    "\n",
    "### Generating the Individuals\n",
    "\n",
    "Let's start with the function that generates individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(random, args):\n",
    "    return [random.uniform(-20, 20), random.uniform(-20, 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The Fitness Function\n",
    "\n",
    "Next the function which evaluates the population. Let's iterate over all the individuals and call function ``criterion`` for each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(candidates, args):\n",
    "    return [criterion(*can) for can in candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Running the Genetic Algorithm\n",
    "\n",
    "Next we are ready to run the genetic algorithm itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "outputs": [],
   "source": [
    "ga = inspyred.ec.GA(Random())\n",
    "# We will want to archive the best solution\n",
    "ga.archiver = inspyred.ec.archivers.best_archiver\n",
    "# We will use blend_crossover and gaussian_mutation as our genetic operators\n",
    "ga.variator = [inspyred.ec.variators.blend_crossover, \n",
    "               inspyred.ec.variators.gaussian_mutation]\n",
    "# We will use tournament selection as our selection method\n",
    "ga.selector = inspyred.ec.selectors.tournament_selection\n",
    "# Evolution will terminate after a certain number of generations\n",
    "ga.terminator = inspyred.ec.terminators.generation_termination\n",
    "\n",
    "# We run the evolution\n",
    "final_pop = ga.evolve(generator=generator, # generating the initial population\n",
    "                      evaluator=evaluator, # evaluating populations\n",
    "                      pop_size=100, # population size\n",
    "                      maximize=False, # are we maximizing or minimizing?\n",
    "                      max_generations=200, # the maximum number of generations\n",
    "                      num_elites=1, # the number of elite individuals (they will get\n",
    "                                    # copied into the next generation without modification)\n",
    "                      tournament_size=3 # size of the tournament (for tournament selection)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Evaluating the Results\n",
    "\n",
    "We will next print the fittest individual from the archive and its fitness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = ga.archive[0]\n",
    "\n",
    "print(\"Ind.: {}\\nFitness: {}\".format(\n",
    "    best_ind.candidate, best_ind.fitness\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "We can also plot all the individuals from the last generation (in red) and the fittest individual (in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, zz, 20, cmap='Blues')\n",
    "plt.colorbar(label=\"z\")\n",
    "\n",
    "points = np.array([ii.candidate for ii in final_pop])\n",
    "\n",
    "plt.scatter(\n",
    "    points[:, 0], points[:, 1],\n",
    "    linewidths=1, edgecolors='k',\n",
    "    s=80,\n",
    "    color='r'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    best_ind.candidate[0],\n",
    "    best_ind.candidate[1],\n",
    "    linewidths=1, edgecolors='k',\n",
    "    s=100,\n",
    "    color='g'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"x\"); plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
